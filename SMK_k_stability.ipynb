{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMK Dataset: k-Stability Experiments\n",
    "Experiments to show that there exist features that are k-unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "Load the SMK dataset. There are 187 instances, 19993 features and a binary outcome variable in the set \\{1, 2\\}. We standardize by subtracting the mean and dividing by the std. deviation.\n",
    "\n",
    "The SMK data set contains 187 smokers either with or without lung cancer. Each of the 19993 features represents one gene in each smoker, and the outcome variable represents lung cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187, 19993)\n",
      "(187, 1)\n",
      "[[10.697  5.345  7.142 ...  5.209  7.569  6.748]\n",
      " [10.424  5.463  7.246 ...  4.215  8.01   6.859]\n",
      " [10.374  5.482  7.815 ...  4.249  8.144  6.928]\n",
      " [10.5    5.584  7.404 ...  4.582  7.526  6.966]\n",
      " [ 9.82   5.612  7.511 ...  4.619  8.983  7.247]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "mat_file = sio.loadmat('./data/SMK_CAN_187.mat')\n",
    "X = mat_file['X']\n",
    "y = mat_file['Y']\n",
    "print(np.shape(X))\n",
    "print(np.shape(y))\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22079395 -1.2754427  -1.17996428 ...  1.36877403 -0.850822\n",
      "  -0.92880521]\n",
      " [ 0.57804618 -0.80677576 -0.74875782 ... -1.43159776  0.22351176\n",
      "  -0.55180162]\n",
      " [ 0.46032681 -0.73131244  1.61043906 ... -1.3358104   0.54995331\n",
      "  -0.31744803]\n",
      " [ 0.75697963 -0.32619355 -0.0936557  ... -0.39765768 -0.95557563\n",
      "  -0.18838374]\n",
      " [-0.84400383 -0.21498445  0.34998941 ... -0.29341848  2.59386719\n",
      "   0.76601274]]\n",
      "[[-1.03816077]\n",
      " [-1.03816077]\n",
      " [-1.03816077]\n",
      " [-1.03816077]\n",
      " [-1.03816077]]\n"
     ]
    }
   ],
   "source": [
    "# normalize the dataset \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y_mean = np.mean(y)\n",
    "y_std = np.std(y)\n",
    "y = (y - y_mean)/y_std\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO Model\n",
    "We use Lasso Regression to find the k-unstable features. Following optimization problem:\n",
    "\n",
    "$$\\min_{\\theta} \\frac{1}{n} \\cdot \\|Y - X\\theta|_2^2 + \\frac{2\\lambda}{n} \\cdot \\|\\theta\\|_1$$\n",
    "\n",
    "Because Lasso induces sparsity on the resulting $\\theta$ vector of the model (typically used for feature selection), we find all the features that get set to 0, and call this our \"target set.\" We aim to loop through the features in our \"target set\" and find the smallest value of $k$ (the number of poison rows) that adds that specific feature to $\\theta$. \n",
    "\n",
    "sklearn's implementation of LASSO, that we're using here, is the following equivalent optimization problem, with hyperparameter $\\alpha$:\n",
    "\n",
    "$$\\min_{\\theta} \\frac{1}{2n} \\|Y - X \\theta\\|_2^2 + \\alpha \\|\\theta\\|_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  298  1653  1768  2343  2424  2595  2709  2714  2784  3054  3562  3790\n",
      "  3918  4155  4735  5496  5701  6577  6757  8627  8679  8889  8905  9032\n",
      "  9145  9382  9698 10309 10526 10597 10650 10738 11083 11146 11148 11161\n",
      " 11249 11331 11563 11583 11652 11776 12384 12396 12411 12502 12641 13491\n",
      " 13575 13664 14301 14773 15368 15700 15705 16260 16397 16542 16785 17071\n",
      " 17842 19625 19757]\n",
      "Number of positive nonzero entries at alpha=0.05: 63\n"
     ]
    }
   ],
   "source": [
    "# TODO: get a more systematic way to find alpha\n",
    "alpha_val = 0.05\n",
    "lasso = Lasso(alpha=alpha_val) # default: alpha = 1.0\n",
    "lasso_coef = lasso.fit(X,y).coef_\n",
    "print(np.where(lasso_coef > 0)[0])\n",
    "print(\"Number of positive nonzero entries at alpha={}: {}\".format(alpha_val, len(lasso_coef[lasso_coef > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 19990 19991 19992]\n",
      "19886\n"
     ]
    }
   ],
   "source": [
    "# Initialize the support and set of poisoning targets\n",
    "support = np.where(abs(lasso_coef) > 1.e-6)[0]\n",
    "target_set = np.where(abs(lasso_coef) <= 1e-6)[0]\n",
    "print(target_set)\n",
    "print(len(target_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because SMK is too big, take 5,000 random features instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[16224 11557 10115 ...  8053  8907 17693]\n"
     ]
    }
   ],
   "source": [
    "target_set = np.random.choice(target_set, 5000, replace=False)\n",
    "print(len(target_set))\n",
    "print(target_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisoning Attack\n",
    "We follow the poisoning attack proposed in **Theorem 4.5** and **Construction 4.6**. That is, for some $k$, the number of posion rows, we generate:\n",
    "\n",
    "$$X_p = \\left[ {\\begin{array}{cccc}\n",
    "   0 & \\dots & 1 & \\dots & 0 \\\\\n",
    "   \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   0 & \\dots & 1 & \\dots & 0 \\\\\n",
    "  \\end{array} } \n",
    "  \\right]\n",
    "$$\n",
    "\n",
    "for the features of our attack, and \n",
    "\n",
    "$$Y_p = \\left[ {\\begin{array}{c}\n",
    "   1 \\\\\n",
    "   \\vdots \\\\\n",
    "   1\n",
    "  \\end{array} } \n",
    "  \\right]\n",
    "$$\n",
    "\n",
    "for the outcome variable of our attack. Then, for $X_0$ and $Y_0$ our original dataset, we append the poison rows $X_p$ and $Y_p$ to get:\n",
    "\n",
    "$$\\left[ {\\begin{array}{c|c}\n",
    "   X_0 & Y_0 \\\\\n",
    "   X_p & Y_p \\\\\n",
    "  \\end{array} } \n",
    "  \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the number of rows to poison, fits a LASSO on the poisoned dataset\n",
    "def poisoned_lasso(target, poison_rows, X, y): \n",
    "    # Generate poison vectors\n",
    "    X_poison = np.zeros(shape=(poison_rows, len(X[0])))\n",
    "    X_poison[:, target] += 1 # switch last column to 1's\n",
    "    y_poison = np.ones(poison_rows)        \n",
    "\n",
    "    # Poisoned datasets\n",
    "    X_poisoned = np.vstack([X, X_poison])\n",
    "    y_poisoned = np.append(y, y_poison)\n",
    "    \n",
    "    poisoned_lasso = lasso.fit(X_poisoned,y_poisoned)\n",
    "    return poisoned_lasso.coef_[target], poisoned_lasso.coef_\n",
    "\n",
    "def plot_features_k_full(target_k_dict):\n",
    "    mean_k = np.asarray(list(target_k_dict.values())).mean()\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    \n",
    "    # Set color of minimum feature\n",
    "    colors = ['c']*len(list(target_k_dict.values()))\n",
    "    colors[0] = 'r'\n",
    "            \n",
    "    plt.bar(range(len(target_k_dict)), list(target_k_dict.values()), align='center', color=colors)\n",
    "    x_ticks = []\n",
    "    #for key in list(target_k_dict.keys()):\n",
    "    #    x_ticks.append(str(key))\n",
    "    #plt.xticks(range(len(target_k_dict)), x_ticks, rotation=90)\n",
    "    plt.xticks([], [])\n",
    "    plt.axhline(y=mean_k,linewidth=1, color='r')\n",
    "    plt.xlabel(\"Features Not in Supp\")\n",
    "    plt.ylabel(\"Minimum k to add to Supp\")\n",
    "    plt.show()\n",
    "    \n",
    "def plot_features_k_random_subset(target_k_dict, size):\n",
    "    mean_k = np.asarray(list(target_k_dict.values())).mean()\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    \n",
    "    # Set color of minimum feature\n",
    "    colors = ['c']*len(list(target_k_dict.values()))\n",
    "    colors[0] = 'r'\n",
    "    \n",
    "    min_feature = list(target_k_dict.keys())[0]\n",
    "    min_value = list(target_k_dict.values())[0]\n",
    "    \n",
    "    # Randomly sample 'size' number of features to graph (NOT including the minimum)\n",
    "    target_keys = list(target_k_dict.keys()).copy()\n",
    "    target_keys.remove(min_feature)\n",
    "    subset_features = np.random.choice(target_keys, size, replace=False)\n",
    "    subset_values = []\n",
    "    for feature in subset_features:\n",
    "        subset_values.append(target_k_dict[feature])\n",
    "        \n",
    "    # Append min feature and value to start of lists\n",
    "    subset_features = np.insert(subset_features, 0, min_feature)\n",
    "    subset_values = np.insert(subset_values, 0, min_value)\n",
    "    \n",
    "    plt.bar(range(len(subset_features)), subset_values, align='center', color=colors)\n",
    "    x_ticks = []\n",
    "    for key in subset_features:\n",
    "        x_ticks.append(str(key))\n",
    "    plt.xticks(range(len(subset_features)), x_ticks, rotation=90)\n",
    "    plt.axhline(y=mean_k,linewidth=1, color='r')\n",
    "    plt.title(\"SMK k-stability\")\n",
    "    plt.xlabel(\"Features Not in Supp\")\n",
    "    plt.ylabel(\"Minimum k to add to Supp\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup\n",
    "We aim to find features that exhibit k-unstability, as compared to the other features in our dataset. To do this, we iteratively attempt the poison attack on each feature $i$, varying $k$ (the number of rows in our poison attack) until we find the smallest $k$ that adds $i$ to the sparse LASSO vector (\"adding\" meaning making its value positive). Do this for each feature. \n",
    "\n",
    "Because there are 19,993 features, we do this on random subsets of 50 features from the 19,993. We take 5 of these subsets and check the results.\n",
    "\n",
    "Conjecture: there exist some features that are much more k-unstable than others, i.e. the $k$ needed to poison that feature is substantially lower than the average value of $k$ across all features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Search for k-values\n",
    "# can't really do this because, at some point, they just all go to 0 again. \n",
    "# one possible solution if we really need binary search: try over a set of possible K_RANGES\n",
    "K_RANGE = 1000\n",
    "k_values = list(range(K_RANGE))\n",
    "target_k_dict = dict()\n",
    "\n",
    "for target in target_set:\n",
    "    first = 0\n",
    "    last = K_RANGE - 1\n",
    "    found = False\n",
    "    while(first <= last and not found):\n",
    "        mid = (first + last)//2\n",
    "        coef, _ = poisoned_lasso(target, mid, X, y)\n",
    "        if(abs(coef) > 1e-6):\n",
    "            prev_coef, _ = poisoned_lasso(target, mid - 1, X, y)\n",
    "            if(abs(prev_coef) <= 1e-6):\n",
    "                found = True\n",
    "                target_k_dict[target] = mid\n",
    "            else:\n",
    "                last = mid - 1\n",
    "        else:\n",
    "            first = mid + 1\n",
    "            \n",
    "sorted_target_k_dict = {k: v for k, v in sorted(target_k_dict.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for all the features\n",
    "plot_features_k_full(sorted_target_k_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for random subset of size\n",
    "size = 50\n",
    "plot_features_k_random_subset(sorted_target_k_dict, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for plotting the final images\n",
    "import pickle\n",
    "with open('SMK_dict.pkl', 'wb') as file:\n",
    "    pickle.dump(sorted_target_k_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
